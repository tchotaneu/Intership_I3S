\setcounter{secnumdepth}{2}


\chapter{Chapter 2: Etat de l'Art}

    \section{Introduction}
    Dans l'analyse et le traitement des données, il est crucial de comprendre les interactions et les corrélations entre différents ensembles de données. L'approche des embeddings multi-vues se distingue par son efficacité et sa flexibilité, jouant un rôle essentiel dans l'intégration d'ensembles de données hétérogènes. Cette méthode offre une représentation unifiée et globale qui saisit avec précision la complexité des données. Cette capacité est particulièrement utile pour extraire des informations pertinentes lors du traitement de données, que ce soit pour le regroupement (clustering), la classification ou la prédiction de liens. Compte tenu de l'importance d'intégrer les données dans un espace unifié, de nombreuses théories ont été élaborées, donnant naissance à des modèles à la fois robustes et efficaces.
    
    \section{Théories et modèles existants}  
   
        \subsection{Notion de Multivues}
            La notion de multivues fait référence à une approche analytique dans laquelle plusieurs "vues" ou représentations d'un même ensemble de données sont examinées et intégrées pour obtenir une compréhension plus profonde et détaillée. Cette méthode est extrêmement utile dans les domaines caractérisés par des données complexes et multidimensionnelles. Prenons l'exemple de la bioinformatique : une vue peut représenter des données génomiques, tandis qu'une autre pourrait se concentrer sur les données protéomiques ou transcriptomiques du même échantillon biologique. L'approche multivues permet d'analyser ces différentes perspectives simultanément, offrant ainsi une compréhension plus complète et nuancée du sujet étudié. Cette méthode diffère fondamentalement de l'approche univue, qui se limite à une seule perspective des données. En intégrant diverses vues, les chercheurs peuvent identifier des corrélations et des interactions qui ne seraient pas évidentes en examinant les vues séparément. Cela conduit à des insights plus riches et ouvre la voie à de nouvelles découvertes dans leur domaine de recherche.
            
            L'importance d'intégrer diverses sources d'information dans un cadre unifié a conduit au développement de nombreuses théories, parfois basées sur des principes statistiques et probabilistes. Parmi cet éventail de concepts, quatre ont particulièrement retenu notre attention, chacun apportant une perspective unique et enrichissante à notre compréhension du multivues. Ces théories nous permettent de naviguer et d'exploiter efficacement la complexité inhérente aux données multidimensionnelles, ouvrant ainsi de nouvelles voies dans la recherche et l'analyse de données.
        \subsection{ Factorisation Matricielle par des Composants Liés pour l'Intégration Unifié}

            Dans leur approche de la  "Factorisation Matricielle par des Composants Liés pour l'Intégration Unifiée",\cite{IrinaGen2017} apportent une contribution notable avec leur modèle SLIDE (Structural Learning and Integrative DEcomposition). Ce modèle se distingue par l'intégration de structures partiellement partagées dans la factorisation matricielle des données multivues, une avancée par rapport au modèle JIVE (Joint and Individual Variation Explained)\cite{Lock2013JIVE}. En fait dans la pluspart des un ensembles multivues reels , il existe des donnees dont les instances ne sont pas presents dans toute les vues .  
                
            SLIDE offre une représentation efficace des données multivues à travers des composants liés, utilisée pour la réduction dimensionnelle exploratoire et l'analyse d'association entre les vues. Cette intégration de composants partiellement partagés aborde un défi important dans la factorisation structurale des données multivues. Dans les études empiriques, notamment avec des données sur le cancer issues du répertoire "The Cancer Genome Atlas", Le modele SLIDE a démontré d'excellentes performances en termes d'estimation du signal et de sélection des composants.

            Cependant, SLIDE présente des limitations. La méthode de détermination du nombre de composants pour chaque type (partagés, individuels, partiellement partagés) pour chaque vue, bien qu'innovante, peut rencontrer des difficultés en termes de complexité computationnelle et de précision dans des contextes de données variés. De plus, l'utilisation d'un cadre de factorisation matricielle pénalisée pour réduire la complexité peut limiter la flexibilité et l'adaptabilité du modèle dans certaines applications.
                
             Ces limitations ouvrent la voie à l'exploration de nouvelles théories pour unifier les données multivues dans un cadre unifié, suggérant la nécessité de modèles plus flexibles et adaptatifs.
                
        \subsection{ La Théorie Basée sur les cadre  de probabiliste }

            La transformation des données issues de différentes vues dans un espace unifié, appelé espace partagé, est un processus fondamental dans le domaine de l'apprentissage automatique. Le modèle \textbf{Probabilistic Multi-view Graph Embedding (PMvGE)}\cite{Okuno18}offre une solution innovante à ce défi, en combinant des techniques avancées d'incorporation de graphes (graph embedding) avec des approches probabilistes pour unifier les données multivues dans un espace commun.
            
            Dans le cadre de PMvGE, les données de chaque vue sont initialement transformées en vecteurs de caractéristiques au sein d'un espace partagé. Cette étape est essentielle pour aligner les données provenant de sources diverses. Elle est effectuée à l'aide de réseaux neuronaux, où les données d'entrée \( x^{(v)} \) sont converties en vecteurs de caractéristiques \( y^{(v)} \) dans l'espace partagé selon la fonction 
            
             \begin{equation}
               y^{(v)} = f^{(v)}(x^{(v)}; \theta^{(v)})
             \end{equation}

        
            Le cœur de PMvGE réside dans sa capacité à modéliser la probabilité d'association entre des paires de vecteurs de caractéristiques issus de différentes vues. Cette probabilité est estimée par le produit scalaire des vecteurs de caractéristiques, exprimé par 
                \begin{equation}
                       P(y^{(v)}, y^{(u)}) = \sigma(y^{(v)T} y^{(u)})
                 \end{equation}
    
            Cette méthode probabiliste dans le cas de l'implementation pourrai etre une sigmoid , cela  permettrai  non seulement d'identifier les associations entre les données, mais aussi d'en quantifier la force.
            
            L'approche probabiliste pour modéliser les associations entre les vecteurs de caractéristiques est un élément clé de PMvGE. Elle permet de détecter et de mesurer la force des associations entre les données de différentes vues, offrant ainsi une compréhension plus détaillée des relations entre les données. L'objectif principal de PMvGE est de maximiser la vraisemblance des associations observées dans les données multivues. La fonction de vraisemblance \( L(\theta) \) est optimisée pour ajuster les paramètres du modèle, suivant l'équation :
            \begin{equation}
                 L(\theta) = \sum_{v,u} \sum_{i,j} w_{ij}^{(vu)} \log P(y_i^{(v)}, y_j^{(u)}; \theta) + (1 - w_{ij}^{(vu)}) \log (1 - P(y_i^{(v)}, y_j^{(u)}; \theta)) 
            \end{equation}
        
        Cette optimisation est cruciale pour assurer que le modèle reflète fidèlement les relations complexes entre les données multivue pour ce distingue des autres mmodeles. \textbf{PMvGE} (Probabilistic Multi-view Graph Embedding) se distingue de CDMCA par l'introduction de transformations non linéaires. Les réseaux neuronaux employe par  PMvGE transformer les données de chaque vue en vecteurs de caractéristiques dans un espace partagé. Cette approche non linéaire permet à PMvGE de capturer des associations plus complexes et subtiles entre les vues, surpassant ainsi les capacités de CDMCA.
        En exploitant des concepts d'incorporation de graphes et de modélisation probabiliste, PMvGE facilite une analyse approfondie et une compréhension des données multivues. Toutefois, la transformation des données via des réseaux neuronaux peut être complexe et nécessite un ajustement précis des paramètres. De plus, la performance du modèle peut être limitée par la taille et la qualité des données disponibles.
        
        Ces limitations soulignent l'importance de développer de nouvelles méthodes pour l'intégration de données multivues, incluant des techniques d'apprentissage plus simples 

        \subsection{La Théorie Basée sur les Méthodes de Conflation de distribution de probabilité:}
        Le concept de conflation de distributions de probabilité joue un rôle essentiel dans la création d'embeddings unifiés. Cette approche, axée sur l'intégration et la fusion de données multivues en une représentation unifiée, repose sur deux principes fondamentaux : la symétrie probabiliste et la réduction de la divergence de Kullback-Leibler. Dans ce contexte, chaque vue possède sa propre distribution de probabilité. Ces distributions sont calculées avant la fusion des données. Après cette fusion, une nouvelle distribution est obtenue dans l'espace unifié. Cela contraste avec les modèles probabilistes qui calculent la probabilité directement dans l'espace unifié.
        
 
        
        \begin{enumerate}
        \item {Probabilité Symétrique}
            \begin{itemize}
                \item Chaque point dans un ensemble de données, relatif à une vue spécifique, calcule une probabilité symétrique pour chaque autre point potentiellement voisin.
                \item La probabilité, notée \( p_{ij}^v \), est déterminée par une formule basée sur l'exponentielle de la dissimilarité au carré entre les points, divisée par la somme de ces exponentielles pour tous les voisins potentiels.
                \item La formule spécifique est : 
                \begin{equation}
                     p_{ij}^v = \frac{\exp{(-d_{ij}^v)^2}}{\sum_{k}{\exp{(-d_{ik}^v)^2}}} \
                \end{equation}
                
                
                où \( d_{ij}^v \) désigne la dissimilarité entre les échantillons \( i \) et \( j \) dans la vue \( v \).
            \end{itemize}
        
        \item {Réduction de la Divergence de Kullback-Leibler}
            \begin{itemize}
                \item L'objectif est de minimiser la divergence de Kullback-Leibler entre la distribution de probabilité dans l'espace de haute dimension et sa contrepartie dans l'espace de basse dimension (embedding).
                \item Cette minimisation est cruciale pour optimiser l'embedding afin qu'il représente fidèlement les relations de probabilité des points dans l'espace de haute dimension.
                \item La divergence est exprimée par :
                \[ C = KL(P || Q) = \sum_{i, j} p_{ij} \log \frac{p_{ij}}{q_{ij}} \].
            \end{itemize}
        \end{enumerate}
    
        Ce processus utilise des principes de probabilité et d'optimisation pour transformer efficacement des données multi-vues de haute dimension en un espace unifié de basse dimension, préservant ainsi la structure essentielle des données originelles.

        \subsection{La Théorie Basée sur les Méthodes de Collaboration de données:} 
    
        Cette approche se concentre sur l'analyse collaborative des données afin de construire un embedding unifié. Elle repose sur trois propriétés essentielles pour explorer les interactions et relations entre les données dans différentes vues. Ces propriétés sont : la diversité, la collaboration de premier ordre et la collaboration de second ordre
        \begin{enumerate}
             \item \textbf{Diversité}
             
            Cette phase vise à capturer l'unicité de chaque vue en produisant des paires d'échantillons ou individus qui sont réellement connectés au sein de chaque vue. Ces paires illustrent la similarité entre les échantillons dans une vue donnée. Pour une vue \( v \), un ensemble de paires intra-vue \( \Omega(v) \) est constitué, chaque paire \( (u(v), w(v)) \in \Omega(v) \) comprenant un échantillon central \( u(v) \) et un échantillon contextuel \( w(v) \). L'objectif est d'optimiser la probabilité de prédire l'échantillon contextuel à partir de l'échantillon central, en réduisant la perte \( Div(\Theta) \), définie comme :
                \begin{equation}
                  L_{Div}(\Theta) = -\sum_{v \in V} \sum_{(i(v), j(v)) \in \Omega(v)} \log P(j(v)|i(v); \Theta)
                \end{equation}
            
             \item \textbf {Collaboration de Premier Ordre}

            Bien que les différentes vues d'un réseau multi-vues présentent de la diversité, elles convergent finalement vers un ensemble commun d'individu ou echantillon. Les instances d'un même individu à travers différentes vues décrivent fondamentalement la même entité.       Cette collaboration de premier ordre  vise à aligner les représentations spécifiques d'un même échantillon à travers différentes vues. Pour ce faire, des paires intra-échantillon sont formées pour toute les vues dans lequelle l'instance de l'echantillon existe. Cette relation peut etre vue comme une relation identitaire car chaque paire représente le même individu observé dans différentes vues. Ainsi, nous avons les paires \( (u(v), u(v')) \), où
            \begin{itemize}
                \item  \( u(v) \) est l'échantillon dans la vue \( v \) 
                \item   \( u(v') \) est l'échantillon  dans la vue \( v' \). 
            \end{itemize}
           
            Comme il s'agit du même individu observé sous différentes perspectives, la perte \( C1(\Theta) \) est minimiser  pour maximiser la similarité des représentations vectorielles de l'échantillon dans les différentes vues. Cette  perte \( C1(\Theta) \) est exprimée de la manière suivante :
    
            \begin{equation}
                L_{C1}(\Theta) = -\sum_{v \in V} \sum_{(i(v), \cdot) \in \Omega(v)} \sum_{v' \neq v} \log P(i(v') | i(v); \Theta)
            \end{equation}
           ou 
               \begin{itemize}
                \item \( P(i(v') | i(v); \Theta) \) exprime la probabilité de prédire correctement la représentation d'un nœud dans une vue \( v' \), en fonction de sa représentation dans une vue \( v \), sous les paramètres \( \Theta \).
                \item \( i(v) \) et \( i(v') \) indiquent respectivement le nœud central dans la vue \( v \) et sa représentation dans une autre vue \( v' \).
               \end{itemize}
           
           
            L'objectif de cette fonction de perte \( L_{C1}(\Theta) \) est de garantir que les embeddings d'un même nœud soient similaires à travers les différentes vues. En optimisant cette fonction, le modèle aligne efficacement les représentations de chaque nœud à travers les vues, assurant ainsi que les caractéristiques fondamentales du nœud sont cohérentes et fidèlement représentées dans l'ensemble du réseau multi-vues.

            
             \item \textbf{Collaboration de Second Ordre}
             
            Cette collaboration utilise les associations entre les échantillons d'une vue pour améliorer la collaboration entre différentes vues. Des paires d'échantillons croisées sont établies selon les associations entre les échantillons de chaque vue, dans le but de mettre à jour les représentations d'un échantillon pour qu'elles ressemblent à celles des échantillons associés dans une autre vue. La perte \( C2(\Theta) \) est minimisée et formulée comme suit :
            
            \begin{equation}
                L_{C2}(\Theta) = -\sum_{v \in V} \sum_{(i(v), j(v)) \in \Omega(v)} \sum_{v' \neq v} \log P(j(v') | i(v); \Theta)
            \end{equation}        
        \end{enumerate} 
        En combinant ces different proprieté de  de collaboration de données , la méthode développe un embedding unifié qui intègre la diversité intrinsèque à chaque vue et la collaboration entre les vues, tout en prenant en compte les relations de second ordre entre les échantillons.
        
      
        
        

    \section{Présentation des principaux modèles generant les embbedding multivues}


            \subsection{Le modele MvNE (Multi-view Neighbourhood Embedding) }
            
            Le modele  Multi-view Neighbourhood Embedding (MvNE) représente une approche sophistiquée pour l'intégration unifiée de données multi-vues. Cette méthode se décompose en plusieurs étapes clés.
            \begin{enumerate}
                \item{Génération de l'ensemble de données unifié:}
                
                    La première étape implique la fusion des différentes vues de l'ensemble de données en une seule représentation unifiée. Chaque vue capte un aspect distinct des données. En cas d'absence de certaines caractéristiques ou échantillons dans des vues, ils seront  remplacés par des valeurs nulles. Ainsi, l'ensemble de données unifié englobe l'intégralité des échantillons et caractéristiques issues des diverses vues.
                    
                \item{Autoencodeur empilé (SAE) pour l'intégration initiale:}
                
                    L'autoencodeur empilé (SAE) est un modèle d'apprentissage profond non supervisé. Il sera  utilisé sur l'ensemble de données unifié pour generer l'embedding initiale . Le SAE se compose d'un encodeur et d'un décodeur. L'encodeur transforme les données d'entrée en un espace de dimension réduite, formant ainsi l'embedding initial. Et le Decodeur du SAE essayer de reconstitue l'echantillon originale à partir de sa representation fournit par l'Encodeur . Le modèle SAE sera  entraîné en minimisant l'erreur de reconstruction sur la différence entre les données d'entrée \(x\) et la sortie reconstruite \(\hat{x}\), mesurée par l'erreur quadratique moyenne suivante :
                    \begin{equation}
                      \text{MSE} = \frac{1}{n}\sum_{i=1}^{n}(x_i - \hat{x}_i)^2
                    \end{equation}
               % end:      #####################
                \item\textbf{Génération de distributions de probabilités unifiées de l'ensemble de données concaténé:}
       
                    Pour chaque échantillon de l'ensemble de données unifié, des probabilités symétriques \( p_{ij} \) sont calculées afin d'estimer la probabilité de sélectionner un point voisin. La formule est la suivante :
                     \begin{equation}
                           p_{ij} = \frac{\prod_v p_{v_{ij}}}{\prod_v p_{v_{ij}} + \prod_v \sum_{k \neq j} p_{v_{ik}}}
                    \end{equation}
        
                    \begin{itemize}
                      \item \( p_{ij} \) : Probabilité combinée que l'échantillon \( i \) choisisse l'échantillon \( j \) comme voisin, en tenant compte de toutes les vues.
                      \item \( \prod_v p_{v_{ij}} \) : Produit des probabilités \( p_{v_{ij}} \) sur toutes les vues \( v \). Chaque \( p_{v_{ij}} \) indique la probabilité que, dans la vue \( v \), l'échantillon \( i \) choisisse \( j \) comme voisin.
                      \item \( \prod_v \sum_{k \neq j} p_{v_{ik}} \) : Produit des sommes des probabilités que l'échantillon \( i \) choisisse un autre échantillon \( k \) (différent de \( j \)) comme voisin, calculé pour chaque vue \( v \).
                    \end{itemize}
            
                    Les probabilités \( p_{v_{ij}} \), basées sur une distribution gaussienne, sont préalablement calculées séparément pour chaque vue. La probabilité est donnée par 
                        \begin{equation}
                             p_{ij}^v = \frac{\exp{(-d_{ij}^v)^2}}{\sum_{k}{\exp{(-d_{ik}^v)^2}}} 
                         \end{equation}
                    où \( d_{ij}^v \) représente la dissimilarité entre les échantillons \( i \) et \( j \) dans la vue \( v \). 
                    
                    Cette approche est particulièrement pertinente dans les scénarios nécessitant l'intégration de données provenant de sources diverses pour obtenir une vue complète et unifiée, comme dans l'analyse de données multi-omiques ou la fusion de données issues de capteurs multiples.

            
            \item\textbf{Génération de distributions de probabilités dans l'espace intégré:} 
                
               Dans cette étape, nous calculons la probabilité symétrique \( q_{ij} \) pour chaque échantillon dans l'espace latent de l'Autoencodeur empilé (SAE). Cette probabilité représente la chance que le point \( i \) sélectionne le point \( j \) comme voisin. Elle est basée sur une distribution de Student t. L'équation correspondante est 
               \begin{equation}
                 q_{ij} = \frac{{1 + \lVert y_i - y_j \rVert^2}^{-1}}{\sum_{l \neq k}{(1 + \lVert y_l - y_k \rVert^2)^{-1}}} 
               \end{equation}
               , 
               où \( y_i \) et \( y_j \) désignent les représentations des points \( i \) et \( j \) dans l'espace d'embedding. La norme \( \lVert y_i - y_j \rVert \) mesure la distance euclidienne entre ces deux points dans cet espace.
            
                Cette formulation permet de capturer les relations de proximité entre les échantillons dans un espace de dimension réduite, facilitant ainsi la compréhension des structures intrinsèques des données multi-vues.
    
            
             \item\textbf{Optimisation de l'intégration unifiée}
                L'objectif final est de trouver un embedding dans un espace à faible dimension qui reflète au mieux la distribution de probabilité unifiée. Cette optimisation est réalisée en minimisant la divergence de Kullback-Leibler (KL) entre la distribution de probabilité unifiée et celle de l'espace intégré. La formule de divergence KL est exprimée par:
                \begin{equation}
                     C = KL(P || Q) = \sum_{i, j} p_{ij} \log \frac{p_{ij}}{q_{ij}}
                \end{equation}
                La descente de gradient est utilisée pour ajuster itérativement la position des échantillons dans l'espace intégré.
        \end{enumerate}
        \subsection{Le modele MANE (Multi-View Collaborative Network Embedding) }
        
        Le modèle MANE, développé pour les réseaux multi-vues, part du principe que ces réseaux sont formés de graphes non orientés. Ce modèle s'appuie sur la théorie des modèles de collaboration de données, en examinant de près les interactions et les relations entre les différentes vues. Il utilise la fonction exponentielle pour calculer les probabilités de prédire avec précision la représentation d'un nœud contextuel en fonction des  nœuds central. les etapes de la contruction de l'embbeding unifié des noeud est la suivantes : 
 % ##############################
       \begin{enumerate}
        
             \item\textbf {Construction de l'Ensemble de Paires de Nœuds }
                
                Cette phase implique la création d'un ensemble de paires de nœuds, divisées en trois catégories :
                \begin{enumerate}
                    \item {Paires de Nœuds Intra-Vue}
                    
                   Pour générer ce type de paires de nœuds, le modèle définit des marches aléatoires au sein de chaque vue afin de générer des séquences de nœuds. Ces séquences ont pour but de révéler la structure topologique de chaque vue. Ensuite, ces séquences sont tronquées en paires de nœuds
                    \item {Paires de Nœuds Inter-Vues Intra-Nœud}
                    
                    Ces paires sont composées d'instances d'un même nœud dans différentes vues.
                    
                    \item {Paires de Nœuds Inter-Vues et Inter-Nœuds}
                    
                    Incluant des paires d'un nœud dans une vue et de différents nœuds dans une autre, ces associations aident à déchiffrer la collaboration de second ordre.   
                \end{enumerate}
                
             \item\textbf{Definir la dimension de la reperesentation vectorielle des noeuds  dans l'espace unifie}
                    
                L'approche MANE consiste à représenter un nœud dans chaque vue, puis à concaténer la représentation de ce nœud dans chaque vue pour former sa représentation finale. L'objectif est de capturer la diversité propre à chaque vue en traitant les opérations sur les paires de nœuds intra-vue de manière distincte. Pour s'assurer que chaque vue contribue de manière égale à la représentation globale du réseau, le cadre conceptuel de MANE divise l'espace d'embedding entre les différentes vues de manière équitable. Elle définit la fonction de représentation de l'embedding dans une vue de la manière suivante :
                    \begin{equation}
                         \left\{ \begin{aligned} f^v &: U \rightarrow \mathbb{R}^{\lfloor D/|V| \rfloor} \\i &\mapsto f_{i(v)} \end{aligned}   \right. 
                    \end{equation}
        
                   \begin{itemize}     
                      \item Ici, \( U \) est l'ensemble des nœuds.
                      \item  \( \mathbb{R}^{\lfloor D/|V| \rfloor} \) est l'ensemble de sortie, représentant l'espace vectoriel dans lequel les embeddings sont placés.
                      \item  \( D \) est la dimension totale de l'espace d'embedding, 
                      \item  \( |V| \) est le nombre de vues dans le réseau.
                      \item  \(f_{i(v)}\) represente le vecteur dense du noeud \( i \) pour la vue \( v\) 
                  \end{itemize}
        
               
            \item\textbf{Calcul de la fonction de Perte pour l'entrainement du modele }
                  \begin{enumerate}
                      \item \textbf{definition de la fontion de perte :}
                      
                        pour prendre en compte la diversité intra-vue ainsi que les interactions inter-vues,le framework MANE utilise une combinaison linéaire de fonctions de pertes consue sur les trois typees d'emsembles de noeuds ( les trois fonctions de pertes definir dans la theories des modeles de collaboration de données ) .  elle est de finide la maniere suivante 
                              \begin{equation}
                                Loss = L_{\text{Div}} + \alpha \cdot L_{C1} + \beta \cdot L_{C2}
                              \end{equation}
                            où :
                             \begin{itemize}
                                \item \( L_{\text{Div}} \) : Représente la perte liée à la diversité intra-vue. Elle vise à capturer la diversité et les caractéristiques uniques de chaque vue individuelle dans le réseau multi-vues.
                                \item \( L_{C1} \) : Correspond à la perte de collaboration de premier ordre. Cette composante de la perte aligne les représentations spécifiques d'un même nœud à travers différentes vues, assurant la cohérence et la similitude des représentations d'un nœud d'une vue à l'autre vue .
                                \item \( L_{C2} \) : Représente la perte de collaboration de second ordre. Elle se concentre sur les relations entre les nœuds à travers différentes vues, exploitant les associations entre les nœuds d'une vue pour renforcer la collaboration entre les différentes vues.
                                \item \( \alpha \) et \( \beta \) : Sont des hyperparamètres qui déterminent l'importance relative des pertes de collaboration de premier et de second ordre par rapport à la perte de diversité. Ces hyperparamètres sont ajustés pour équilibrer le modèle en fonction des particularités du réseau et des objectifs de l'analyse.
                            \end{itemize}
                    \item \textbf{definition de la fonction de probabilité}
                    
                     La probabilité \( P(j(v)|i(v); \Theta) \) est mise en pratique par le modèle MANE via une fonction softmax à travers  l'implemetation de l'equation :
                    \begin{equation}
                      P(j(v) | i(v); \Theta) =  \log \left( \frac{\exp(f_{i(v)} \cdot f_{j(v)})}{\sum_{k \in U} \exp(f_{i(v)} \cdot f_{k(v)})} \right)
                    \end{equation}
                     Où :
                    \begin{itemize}
                        \item \(f_{i(v)} \) est la representation vectoreille dense du noeud \(i\) dans la vue \(v\)
                        \item \(f_{i(v')} \) est la representation vectoreille dense du noeud \(i\) dans la vue \(v'\)
                        \item La fonction exponentielle \( \exp(f_{i(v)} \cdot f_{j(v')}) \) transforme le score de similarité en probabilité.
                         \item \( P(j(v) | i(v); \Theta) \) est la probabilité de prédire correctement la représentation du nœud \( j \) dans une vue \( v' \), en se basant sur sa connexion avec le nœud \( i \) dans la vue \( v \), sous les paramètres du modèle \( \Theta \).
                    \end{itemize}
                      
            \end{enumerate}
                 
               Ainsi , nous aurons expresiion des des differeents 
                 \begin{equation}
                    L_{Div}(\Theta) =-\sum_{v \in V} \sum_{(i(v), j(v)) \in \Omega(v)} \log \left( \frac{\exp(f_{i(v)} \cdot f_{j(v)})}{\sum_{k \in U} \exp(f_{i(v)} \cdot f_{k(v)})} \right)
                \end{equation}
                 \begin{equation}
                    L_{C1}(\Theta)= -\sum_{v \in V} \sum_{(i(v), \cdot) \in \Omega(v)} \sum_{v' \neq v} \log \left( \frac{\exp(f_{i(v)} \cdot f_{i(v')})}{\sum_{k \in U} \exp(f_{k(v)} \cdot f_{i(v')})} \right)
                \end{equation}
                \begin{equation}
                  L_{C2}(\Theta)  = -\sum_{v \in V} \sum_{(i(v), j(v)) \in \Omega(v)} \sum_{v' \neq v} \log \left( \frac{\exp(f_{i(v)} \cdot f_{j(v')})}{\sum_{k \in U} \exp(f_{i(v)} \cdot f_{k(v')})} \right)
                \end{equation}
                Où :
                \begin{itemize}
                    \item \( V \) représente l'ensemble des vues dans le réseau multi-vues.
                    \item \( \Omega(v) \) désigne les paires de nœuds connectés dans la vue \( v \).
                    \item \( i(v) \) et \( j(v) \) sont des nœuds connectés dans la vue \( v \), et \( j(v') \) est la représentation du nœud \( j \) dans une autre vue \( v' \).
                    \item \( U \) est l'ensemble total des nœuds dans le réseau.
                   
                  
                \end{itemize}

        \end{enumerate}











